#Own Model
def conv_relu(filters, kernel_size, strides=(1, 1), padding='same', dropout = 0.001):
    layer = Sequential()
    layer.add(Conv2D(filters = filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False))
    layer.add(BatchNormalization())
    layer.add(Activation('relu'))
    layer.add(Dropout(dropout))
    return layer

def depthwise_conv_relu(kernel_size, strides=(1, 1), padding='same',dropout = 0.001):
    layer = Sequential()
    layer.add(DepthwiseConv2D(kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False))
    layer.add(BatchNormalization())
    layer.add(Activation('relu'))
    layer.add(Dropout(dropout))
    return layer

def aspiring_mobile_net(num_classes, dropout=0.001):
    model = Sequential(name ="TrulyMonstrousModel" )
    # Warstwy konwolucyjne
    model.add(conv_relu(filters=32, kernel_size=(3, 3), strides=(2, 2),dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(1, 1),dropout = dropout))
    model.add(conv_relu(filters=64, kernel_size=(1, 1), strides=(1, 1),dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(2, 2),dropout = dropout))    
    model.add(conv_relu(filters=128, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(1, 1),dropout = dropout))    
    model.add(conv_relu(filters=128, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(2, 2),dropout = dropout))    
    model.add(conv_relu(filters=256, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(1, 1),dropout = dropout))    
    model.add(conv_relu(filters=256, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(2, 2),dropout = dropout))    
    model.add(conv_relu(filters=512, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(2, 2),dropout = dropout))    
    model.add(conv_relu(filters=512, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(2, 2),dropout = dropout))    
    model.add(conv_relu(filters=1024, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))
    model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(2, 2),dropout = dropout))    
    model.add(conv_relu(filters=1024, kernel_size=(1, 1), strides=(1, 1), dropout = dropout))

    # Dodatkowe warstwy konwolucyjne
    for i in range(5):
        model.add(depthwise_conv_relu(kernel_size=(3, 3), strides=(1, 1),dropout = dropout))
        model.add(conv_relu(filters=2048, kernel_size=(1, 1), strides=(1, 1),dropout = dropout))

    # Warstwa poolingowa
    model.add(GlobalAveragePooling2D())

    # Warstwa FC
    model.add(Dropout(0.2))
    model.add(Dense(units=num_classes, activation='softmax'))

    return model
	
	
data_aug = Sequential(layers=[
    Input(shape=(256, 256, 3), name="InputLayer"),
    RandomFlip(mode='horizontal_and_vertical', name="RandomFlip"),
    RandomRotation(factor=10, fill_mode='reflect', name="RandomRotation"),
    RandomContrast(factor=0.5, name="RandomContrast")
], name="DataAugmetor")

base_model = aspiring_mobile_net(num_classes=num_classes)
base_model.trainable = True

# Final model structure
model = Sequential([
    Input(shape=input_shape),
    data_aug,
    base_model,
    Flatten(),
    Reshape((1,1,-1)),
    GAP(),
    Dense(256, activation='relu'),
    Dropout(0.2),
    Dense(5, activation='softmax')
], name="m0d3l")